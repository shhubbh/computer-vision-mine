{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258b1d8c-2ab5-4de5-bb3f-9e8944a8e12b",
   "metadata": {},
   "source": [
    "## To predict the masks of image, generate binary masks, prediction images with bounding boxes and prediction labels for whole test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bfc14f-aa3b-4b0a-9537-d104629f11bf",
   "metadata": {},
   "source": [
    "##### The below codes are run only after creating the Individual LUT_GT_Test GeoJSONs using the GT-YOLOLabel_to_GEOJSON.ipynb code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05dafcae-4355-45d8-8bc4-68f02d8cffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/ubuntu/Desktop/DL_WorkSpace/WorkSpace/Input_Data_Container/Bangkok_Province/Rural_WS/yolo8_segmentation_ws')\n",
    "model_direc =  os.getcwd()\n",
    "#print(model_direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "174f4f22-de82-4303-bdaa-c3166536c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lut = 'Rural_WS'\n",
    "prediction_lut = 'All_Land_Use_Zones_WS'\n",
    "post_processing_direc = 'Rural-M_2_ALUT_Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "abffbfe0-70f2-430d-86ed-616f1c5ddd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_direc = os.path.join('/home/ubuntu/Desktop/DL_WorkSpace/WorkSpace/Input_Data_Container/Bangkok_Province', prediction_lut, 'yolo8_segmentation_ws')\n",
    "#print(test_img_direc)\n",
    "\n",
    "prediction_dir = os.path.join(\"/home/ubuntu/Desktop/DL_WorkSpace/WorkSpace/Input_Data_Container/Bangkok_Province\",model_lut, \"yolo8_segmentation_ws/post_processing\", post_processing_direc)\n",
    "#print(prediction_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5662a0-4861-4075-bc8f-30de5be1767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "custom_model_direc = os.path.join(model_direc, 'runs/segment/train/weights/best.pt')\n",
    "# Load a model\n",
    "model = YOLO(custom_model_direc) \n",
    "\n",
    "#img_dir = os.path.join(home_direc, 'sample')\n",
    "img_dir = os.path.join(test_img_direc, 'test/images')\n",
    "img_list = os.listdir(img_dir)\n",
    "\n",
    "pred_img_save_dir = os.path.join(prediction_dir, 'predict_img') # image save folder\n",
    "os.makedirs(pred_img_save_dir, exist_ok=True)\n",
    "\n",
    "pred_mask_save_dir = os.path.join(prediction_dir, 'predict_mask') # mask save folder\n",
    "os.makedirs(pred_mask_save_dir, exist_ok=True)\n",
    "\n",
    "# Predict for a single image in loop\n",
    "for img in tqdm(img_list):\n",
    "    img_path = os.path.join(img_dir, img)\n",
    "    results = model.predict(img_path, imgsz=640,  save_txt=True, save_conf=False, show_labels=False, iou=0.6,conf=0.25)\n",
    "    if results[0].masks is not None:\n",
    "        boxes = results[0].boxes.xyxy  # Bounding box coordinates\n",
    "        masks = results[0].masks.data.cpu()  # Segmentation masksave=True,s (moved to CPU and converted to NumPy array)\n",
    "        image = cv2.imread(img_path)  # Read the original image\n",
    "        im_array = results[0].plot(boxes= False, labels=False, probs=False)  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        #im.show()  # show image\n",
    "        im.save(os.path.join(pred_img_save_dir, img+'.jpg'))\n",
    "        # Plot the predicted mask\n",
    "        predicted_mask = np.zeros_like(image[:, :, 0])\n",
    "        for mask in masks:\n",
    "            predicted_mask[np.where(mask)] = 255\n",
    "            pd = Image.fromarray(predicted_mask[..., ::])  # RGB PIL image\n",
    "            pd.save(os.path.join(pred_mask_save_dir , img+'.jpg')) # save image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d59d63-fb03-47d9-84dc-2be47772a90c",
   "metadata": {},
   "source": [
    "### Now, the obtained predict folder from the above code which is in segments should be manually copied to \"post_processing_direc\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeee84f-6611-4429-ad4d-3394c4248607",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For example\n",
    "\n",
    "import shutil\n",
    "\n",
    "predict_ws = '/home/ubuntu/Desktop/DL_WorkSpace/WorkSpace/Input_Data_Container/Bangkok_Province/Rural_WS/yolo8_segmentation_ws/runs/segment/predict'\n",
    "new_directory = '/home/ubuntu/Desktop/DL_WorkSpace/WorkSpace/Input_Data_Container/Bangkok_Province/Rural_WS/yolo8_segmentation_ws/post_processing/Rural-M_2_ALUT_Test/'\n",
    "\n",
    "shutil.move(predict_ws, new_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea670f0-9c14-41b5-ac77-1b15a0338408",
   "metadata": {},
   "source": [
    "### Reference Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb667c71-4a90-4a7d-bcec-b59b4c3b6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/ubuntu/Desktop/DL_WorkSpace/WorkSpace/Input_Data_Container/Bangkok_Province/All_Land_Use_Zones_WS/yolo8_segmentation_ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b2adb-889b-4298-97d3-cee1a38c4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_direc = os.getcwd()\n",
    "print(home_direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6667553-72ac-478c-bb7e-6aa1cceedcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "custom_model_direc = os.path.join(home_direc, 'runs/segment/train/weights/best.pt')\n",
    "# Load a model\n",
    "model = YOLO(custom_model_direc) \n",
    "\n",
    "#img_dir = os.path.join(home_direc, 'sample')\n",
    "img_dir = os.path.join(home_direc, 'test/images')\n",
    "img_list = os.listdir(img_dir)\n",
    "\n",
    "pred_img_save_dir = os.path.join(home_direc, 'test_results_ws/alut-M_2_alut', 'predict_img') # image save folder\n",
    "os.makedirs(pred_img_save_dir, exist_ok=True)\n",
    "\n",
    "pred_mask_save_dir = os.path.join(home_direc, 'test_results_ws/alut-M_2_alut', 'predict_mask') # mask save folder\n",
    "os.makedirs(pred_mask_save_dir, exist_ok=True)\n",
    "\n",
    "# Predict for a single image in loop\n",
    "for img in tqdm(img_list):\n",
    "    img_path = os.path.join(img_dir, img)\n",
    "    results = model.predict(img_path, imgsz=640, save_conf=True, show_labels=False, iou=0.5,conf=0.288)\n",
    "    if results[0].masks is not None:\n",
    "        boxes = results[0].boxes.xyxy  # Bounding box coordinates\n",
    "        masks = results[0].masks.data.cpu()  # Segmentation masks (moved to CPU and converted to NumPy array)\n",
    "        image = cv2.imread(img_path)  # Read the original image\n",
    "        im_array = results[0].plot(boxes= False, labels=False, probs=False)  # plot a BGR numpy array of predictions\n",
    "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "        #im.show()  # show image\n",
    "        im.save(os.path.join(pred_img_save_dir, img+'.jpg'))\n",
    "        # Plot the predicted mask\n",
    "        predicted_mask = np.zeros_like(image[:, :, 0])\n",
    "        for mask in masks:\n",
    "            predicted_mask[np.where(mask)] = 255\n",
    "            pd = Image.fromarray(predicted_mask[..., ::])  # RGB PIL image\n",
    "            pd.save(os.path.join(pred_mask_save_dir , img+'.jpg')) # save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68065e1a-0318-4225-a0c3-0063ae6fb5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ultralytics]",
   "language": "python",
   "name": "conda-env-ultralytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
