{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of COCO Dataset\n",
    "\n",
    "### Virtual Environment: remote_sensing_v2 \n",
    "### To create training and validation dataset from tiff and geojson to coco format for training the Instance Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\shubh\\Documents\\Analytics\\Computer Vision\\CB_Analytics_WS\\GIS_WS\\GIS_Roads_WS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\Documents\\Analytics\\Computer Vision\\CB_Analytics_WS\\GIS_WS\\GIS_Roads_WS\n"
     ]
    }
   ],
   "source": [
    "home_direc = os.getcwd()\n",
    "print(home_direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this Notebook from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Below Codes are for converting data to COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm, trange\n",
    "import geopandas as gpd\n",
    "from osgeo import ogr\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Save the raster image\n",
    "def writeTiff(im_data, save_path, new_transform, crs):\n",
    "    _, height, width = im_data.shape\n",
    "    with rasterio.open(save_path,\n",
    "                       'w',\n",
    "                       driver='GTiff',\n",
    "                       height=height,\n",
    "                       width=width,\n",
    "                       count=3,\n",
    "                       dtype=im_data.dtype,\n",
    "                       crs=crs,\n",
    "                       transform=new_transform\n",
    "                       ) as dst:\n",
    "        dst.write(im_data)\n",
    "    return\n",
    "\n",
    "# read the raster image\n",
    "def readTiff(TifPath):\n",
    "    dataset_img = rasterio.open(TifPath)\n",
    "    width = dataset_img.width\n",
    "    height = dataset_img.height\n",
    "    crs = dataset_img.crs\n",
    "    transform = dataset_img.transform # (xres, 0, xcord, 0, yres, ycord)\n",
    "    img_array = dataset_img.read([1, 2, 3]) # get the data\n",
    "    return img_array, width, height, crs, transform\n",
    "\n",
    "# translate Gdal data to opencv format\n",
    "def GdalData2OpencvData(GdalImg_data):\n",
    "    OpencvImg_data = np.zeros((GdalImg_data.shape[1],GdalImg_data.shape[2],GdalImg_data.shape[0]),np.uint8)\n",
    "    for i in range(GdalImg_data.shape[0]):\n",
    "        OpencvImg_data[:,:,i] = GdalImg_data[GdalImg_data.shape[0]-i-1,:,:]\n",
    "    return OpencvImg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm.auto import notebook_tqdm\n",
    "import cv2\n",
    "from sahi.utils.coco import Coco, CocoCategory, CocoImage, CocoAnnotation\n",
    "from sahi.utils.file import save_json\n",
    "\n",
    "def read_tiff(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        im_data = src.read()\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "        crs = src.crs\n",
    "        transform = src.transform\n",
    "    return im_data, width, height, crs, transform\n",
    "\n",
    "def gdal_data_to_opencv_data(im_data):\n",
    "    if len(im_data.shape) == 3:\n",
    "        return np.transpose(im_data, (1, 2, 0))\n",
    "    else:\n",
    "        return im_data\n",
    "\n",
    "#home_direc = os.path.expanduser('~')\n",
    "root_dir = os.path.join(home_direc, 'cropped_tiff')\n",
    "root_geojson_dir = os.path.join(home_direc, 'cropped_geojson')\n",
    "\n",
    "save_dir = os.path.join(home_direc, 'COCO_dataset_WS')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "tif_list = [x for x in os.listdir(root_dir) if x.endswith('.tif')]\n",
    "\n",
    "# Init Coco object:\n",
    "coco = Coco()\n",
    "# Add categories (starting from id 0):\n",
    "category_name = 'road'\n",
    "coco.add_category(CocoCategory(id=0, name=category_name))\n",
    "\n",
    "# Process each TIFF and corresponding GeoJSON file\n",
    "for tif in notebook_tqdm(tif_list):\n",
    "    img_path = os.path.join(root_dir, tif)\n",
    "    im_data, width, height, crs, transform = read_tiff(img_path)\n",
    "    img_name = os.path.splitext(os.path.split(img_path)[-1])[0]\n",
    "    geojson_path = os.path.join(root_geojson_dir, img_name + '.geojson')\n",
    "    \n",
    "    if os.path.exists(geojson_path):\n",
    "        annot_df = gpd.read_file(geojson_path)\n",
    "        \n",
    "        # Coordinates of the upper left corner \n",
    "        x0, y0 = transform[2], transform[5]\n",
    "        xres, yres = transform[0], transform[4]\n",
    "        \n",
    "        # Convert the TIFF file to JPG\n",
    "        im_data = gdal_data_to_opencv_data(im_data)\n",
    "        img_save_dir = os.path.join(save_dir, 'images')\n",
    "        os.makedirs(img_save_dir, exist_ok=True)\n",
    "        img_save_path = os.path.join(img_save_dir, img_name + '.jpg')\n",
    "        cv2.imwrite(img_save_path, im_data)\n",
    "        \n",
    "        # Create a CocoImage\n",
    "        coco_image = CocoImage(file_name=os.path.join(img_name + '.jpg'), height=height, width=width)\n",
    "        \n",
    "        # Add annotations to CocoImage\n",
    "        for polygon in annot_df['geometry']:\n",
    "            seg_list = []\n",
    "            if polygon.geom_type == 'MultiPolygon':\n",
    "                for geom in polygon.geoms:\n",
    "                    segmentation = np.array(geom.exterior.coords)\n",
    "                    segmentation = np.ravel((segmentation - [x0, y0]) / [xres, yres])\n",
    "                    seg_list.append(list(segmentation))\n",
    "            else:\n",
    "                segmentation = np.array(polygon.exterior.coords)\n",
    "                segmentation = np.ravel((segmentation - [x0, y0]) / [xres, yres])\n",
    "                seg_list.append(list(segmentation))\n",
    "            \n",
    "            bbox = np.array(polygon.bounds)\n",
    "            bbox = [bbox[0]-x0, abs(bbox[1]-y0), (bbox[2]-bbox[0]) / xres, abs(bbox[3]-bbox[1]) / yres] # bbox(xmin, ymin, width, height)\n",
    "            coco_image.add_annotation(\n",
    "                CocoAnnotation(\n",
    "                    segmentation=seg_list,\n",
    "                    bbox=bbox,\n",
    "                    category_id=0,\n",
    "                    category_name=category_name\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Add CocoImage to Coco object\n",
    "        coco.add_image(coco_image)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Convert Coco object to JSON and save\n",
    "coco_json = coco.json\n",
    "json_save_path = os.path.join(save_dir, 'coco_dataset.json')\n",
    "save_json(coco_json, json_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b5b6f83b4343df95a57e2a4ba7f9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert geojson to json file in COCO format\n",
    "\n",
    "from unicodedata import category\n",
    "from sahi.utils.coco import Coco, CocoCategory, CocoImage, CocoAnnotation\n",
    "from sahi.utils.file import save_json\n",
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "root_dir = os.path.join(home_direc, 'cropped_tiff') \n",
    "root_geojson_dir = os.path.join(home_direc, 'cropped_geojson') \n",
    "\n",
    "save_dir = os.path.join(home_direc, 'COCO_dataset_WS')   # path to save folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "tif_list = [x for x in os.listdir(root_dir) if x.endswith('.tif')]\n",
    "\n",
    "# Init Coco object:\n",
    "coco = Coco()\n",
    "# Add categories (starting from id 0):\n",
    "category_name = 'road'\n",
    "coco.add_category(CocoCategory(id=0, name=category_name))\n",
    "\n",
    "# read image and geosjon file\n",
    "for tif in tqdm(tif_list):\n",
    "  img_path = os.path.join(root_dir, tif)\n",
    "  im_data, width, height, crs, transform = readTiff(img_path)\n",
    "  img_name = os.path.splitext(os.path.split(img_path)[-1])[0]\n",
    "  geojson_path = os.path.join(root_geojson_dir, img_name + '.geojson')\n",
    "  # judge whether geojson file exist or not\n",
    "  if os.path.exists(geojson_path):\n",
    "    annot_df = gpd.read_file(geojson_path)\n",
    "    # Coordinates of the upper left corner \n",
    "    x0 = transform[2]\n",
    "    y0 = transform[5]\n",
    "    xres = transform[0]\n",
    "    yres = transform[4]\n",
    "    # convert the tif file to jpg\n",
    "    # transfer gdal data to opencv\n",
    "    im_data = GdalData2OpencvData(im_data)\n",
    "    img_save_dir = os.path.join(save_dir, 'images') # image save folder\n",
    "    os.makedirs(img_save_dir, exist_ok=True)\n",
    "    img_save_path = os.path.join(img_save_dir, img_name + '.jpg')\n",
    "    cv2.imwrite(img_save_path, im_data)\n",
    "    # create a coco image:\n",
    "    #coco_image = CocoImage(file_name = os.path.join(root_dir, 'COCO_json/val/image', img_name + '.jpg'), height=height, width=width)\n",
    "    #coco_image = CocoImage(file_name = os.path.join('THA/thailand_img_dir/processed_data/COCO_json/val/image', img_name + '.jpg'), height=height, width=width)\n",
    "    coco_image = CocoImage(file_name = os.path.join(img_name + '.jpg'), height=height, width=width)\n",
    "    #coco_image = CocoImage(file_name = os.path.join(img_save_path), height=height, width=width)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add annotations to CocoImage\n",
    "for polygon in annot_df['geometry']:\n",
    "    seg_list = []\n",
    "    if polygon.geom_type == 'MultiPolygon':\n",
    "        for geom in polygon.geoms:\n",
    "            segmentation = np.array(geom.exterior.coords)\n",
    "            segmentation = np.ravel((segmentation - [x0, y0]) / [xres, yres])\n",
    "            seg_list.append(list(segmentation))\n",
    "    else:\n",
    "        segmentation = np.array(polygon.exterior.coords)  # Get global coordinates\n",
    "        segmentation = np.ravel((segmentation - [x0, y0]) / [xres, yres])  # Convert to local coordinates\n",
    "        seg_list.append(list(segmentation))\n",
    "    \n",
    "    bbox = np.array(polygon.bounds)\n",
    "    bbox = [bbox[0]-x0, abs(bbox[1]-y0), (bbox[2]-bbox[0]) / xres, abs(bbox[3]-bbox[1]) / yres]  # bbox(xmin, ymin, width, height)\n",
    "    coco_image.add_annotation(\n",
    "        CocoAnnotation(\n",
    "            segmentation=seg_list,\n",
    "            bbox=bbox,\n",
    "            category_id=0,\n",
    "            category_name=category_name\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add CocoImage to Coco object\n",
    "coco.add_image(coco_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_json = coco.json\n",
    "json_save_path = os.path.join(save_dir, 'coco_dataset' + '.json')\n",
    "save_json(coco_json, json_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice_coco() missing 1 required positional argument: 'output_coco_annotation_file_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#IGNORE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Slice COCO dataset images and annotations into grids:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msahi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslicing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m slice_coco\n\u001b[0;32m----> 5\u001b[0m coco_dict, coco_path \u001b[38;5;241m=\u001b[39m \u001b[43mslice_coco\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoco_annotation_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco_dataset_ws/coco_dataset.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoco_dataset_ws/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap_height_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap_width_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice_coco() missing 1 required positional argument: 'output_coco_annotation_file_name'"
     ]
    }
   ],
   "source": [
    "#IGNORE\n",
    "#Slice COCO dataset images and annotations into grids:\n",
    "from sahi.slicing import slice_coco\n",
    "\n",
    "coco_dict, coco_path = slice_coco(\n",
    "    coco_annotation_file_path=\"coco_dataset_ws/coco_dataset.json\",\n",
    "    image_dir=\"coco_dataset_ws/images\",\n",
    "    slice_height=640,\n",
    "    slice_width=640,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████| 2386/2386 [00:23<00:00, 102.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#IGNORE\n",
    "#Split COCO dataset into train/val:\n",
    "from sahi.utils.coco import Coco\n",
    "from sahi.utils.file import save_json\n",
    "\n",
    "# specify coco dataset path\n",
    "coco_path = \"coco_dataset_ws/coco_dataset.json\"\n",
    "\n",
    "# init Coco object\n",
    "coco = Coco.from_coco_dict_or_path(coco_path)\n",
    "\n",
    "# split COCO dataset with a 85% train/15% val split\n",
    "result = coco.split_coco_as_train_val(\n",
    "  train_split_rate=0.85\n",
    ")\n",
    "\n",
    "# export train val split files\n",
    "save_json(result[\"train_coco\"].json, \"train_split.json\")\n",
    "save_json(result[\"val_coco\"].json, \"val_split.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████| 7789/7789 [00:40<00:00, 193.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#Filter/Update COCO dataset by categories:\n",
    "from sahi.utils.coco import Coco\n",
    "from sahi.utils.file import save_json\n",
    "\n",
    "# init Coco objects by specifying coco dataset paths and image folder directories\n",
    "coco = Coco.from_coco_dict_or_path(\"coco_dataset_ws/coco_dataset.json\")\n",
    "\n",
    "# select only 3 categories; and map them to ids 1, 2 and 3\n",
    "desired_name2id = {\n",
    "  \"building\": 1\n",
    "}\n",
    "coco.update_categories(desired_name2id)\n",
    "\n",
    "# export updated/filtered COCO dataset\n",
    "save_json(coco.json, \"coco_dataset_ws/updated_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE\n",
    "#Filter COCO dataset by annotation area:\n",
    "from sahi.utils.coco import Coco\n",
    "from sahi.utils.file import save_json\n",
    "\n",
    "# init Coco objects by specifying coco dataset paths and image folder directories\n",
    "coco = Coco.from_coco_dict_or_path(\"coco.json\")\n",
    "\n",
    "# filter out images that contain annotations with smaller area than 50\n",
    "area_filtered_coco = coco.get_area_filtered_coco(min=50)\n",
    "# filter out images that contain annotations with smaller area than 50 and larger area than 10000\n",
    "area_filtered_coco = coco.get_area_filtered_coco(min=50, max=10000)\n",
    "# filter out images with seperate area intervals per category\n",
    "intervals_per_category = {\n",
    "  \"human\": {\"min\": 20, \"max\": 10000},\n",
    "  \"vehicle\": {\"min\": 50, \"max\": 15000},\n",
    "}\n",
    "area_filtered_coco = coco.get_area_filtered_coco(intervals_per_category=intervals_per_category)\n",
    "\n",
    "# export filtered COCO dataset\n",
    "save_json(area_filtered_coco.json, \"area_filtered_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████| 7789/7789 [00:44<00:00, 174.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#Filter out images that does not contain any annotation:\n",
    "from sahi.utils.coco import Coco\n",
    "\n",
    "# set ignore_negative_samples as False if you want images without annotations present in json and yolov5 exports\n",
    "coco = Coco.from_coco_dict_or_path(\"coco_dataset_ws/coco_dataset.json\", ignore_negative_samples=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE\n",
    "#Merge COCO dataset files:\n",
    "from sahi.utils.coco import Coco\n",
    "from sahi.utils.file import save_json\n",
    "\n",
    "# init Coco objects by specifying coco dataset paths and image folder directories\n",
    "coco_1 = Coco.from_coco_dict_or_path(\"coco1.json\", image_dir=\"images_1/\")\n",
    "coco_2 = Coco.from_coco_dict_or_path(\"coco2.json\", image_dir=\"images_2/\")\n",
    "\n",
    "# merge Coco datasets\n",
    "coco_1.merge(coco_2)\n",
    "\n",
    "# export merged COCO dataset\n",
    "save_json(coco_1.json, \"merged_coco.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████| 2386/2386 [00:23<00:00, 100.00it/s]\n",
      "06/11/2023 16:44:48 - INFO - sahi.utils.coco -   generating image symlinks and annotation files for yolov5...\n",
      "100%|██████████████████████████████████████| 2028/2028 [00:11<00:00, 178.57it/s]\n",
      "06/11/2023 16:44:59 - INFO - sahi.utils.coco -   generating image symlinks and annotation files for yolov5...\n",
      "100%|████████████████████████████████████████| 358/358 [00:02<00:00, 172.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert COCO dataset to ultralytics/yolov5 format:\n",
    "from sahi.utils.coco import Coco\n",
    "\n",
    "# init Coco object\n",
    "coco = Coco.from_coco_dict_or_path(\"coco_dataset_ws/coco_dataset.json\", image_dir=\"coco_dataset_ws/images/\")\n",
    "\n",
    "# export converted YoloV5 formatted dataset into given output_dir with a 85% train/15% val split\n",
    "coco.export_as_yolov5(\n",
    "  output_dir=\"output/folder/dir\",\n",
    "  train_split_rate=0.85\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE\n",
    "#Convert train/val COCO dataset to ultralytics/yolov5 format:\n",
    "from sahi.utils.coco import Coco, export_coco_as_yolov5\n",
    "\n",
    "# init Coco object\n",
    "train_coco = Coco.from_coco_dict_or_path(\"train_coco.json\", image_dir=\"coco_images/\")\n",
    "val_coco = Coco.from_coco_dict_or_path(\"val_coco.json\", image_dir=\"coco_images/\")\n",
    "\n",
    "# export converted YoloV5 formatted dataset into given output_dir with given train/val split\n",
    "data_yml_path = export_coco_as_yolov5(\n",
    "  output_dir=\"output/folder/dir\",\n",
    "  train_coco=train_coco,\n",
    "  val_coco=val_coco\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████| 7789/7789 [00:42<00:00, 182.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_images': 7789,\n",
       " 'num_annotations': 446692,\n",
       " 'num_categories': 1,\n",
       " 'num_negative_images': 0,\n",
       " 'num_images_per_category': {'building': 7789},\n",
       " 'num_annotations_per_category': {'building': 446692},\n",
       " 'min_num_annotations_in_image': 1,\n",
       " 'max_num_annotations_in_image': 398,\n",
       " 'avg_num_annotations_in_image': 57.34908203877263,\n",
       " 'min_annotation_area': 0,\n",
       " 'max_annotation_area': 352745,\n",
       " 'avg_annotation_area': 2407.161675158722,\n",
       " 'min_annotation_area_per_category': {'building': 0},\n",
       " 'max_annotation_area_per_category': {'building': 352745}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get dataset stats:\n",
    "from sahi.utils.coco import Coco\n",
    "\n",
    "# init Coco object\n",
    "coco = Coco.from_coco_dict_or_path(\"coco_dataset_ws/coco_dataset.json\")\n",
    "\n",
    "# get dataset stats\n",
    "coco.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|████████████| 7789/7789 [00:40<00:00, 191.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_images': 7789,\n",
       " 'num_annotations': 446692,\n",
       " 'num_categories': 1,\n",
       " 'num_negative_images': 0,\n",
       " 'num_images_per_category': {'building': 7789},\n",
       " 'num_annotations_per_category': {'building': 446692},\n",
       " 'min_num_annotations_in_image': 1,\n",
       " 'max_num_annotations_in_image': 398,\n",
       " 'avg_num_annotations_in_image': 57.34908203877263,\n",
       " 'min_annotation_area': 0,\n",
       " 'max_annotation_area': 352745,\n",
       " 'avg_annotation_area': 2407.161675158722,\n",
       " 'min_annotation_area_per_category': {'building': 0},\n",
       " 'max_annotation_area_per_category': {'building': 352745}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get dataset stats:\n",
    "from sahi.utils.coco import Coco\n",
    "\n",
    "# init Coco object\n",
    "coco = Coco.from_coco_dict_or_path(\"coco_dataset_ws/updated_coco.json\")\n",
    "\n",
    "# get dataset stats\n",
    "coco.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE\n",
    "#Remove invalid coco results:\n",
    "from sahi.utils.file import save_json\n",
    "from sahi.utils.coco import remove_invalid_coco_results\n",
    "\n",
    "# remove invalid predictions from COCO results JSON\n",
    "coco_results = remove_invalid_coco_results(\"coco_dataset_ws/coco_dataset.json\")\n",
    "\n",
    "# export processed COCO results\n",
    "save_json(coco_results, \"coco_dataset_ws/fixed_coco_result.json\")\n",
    "\n",
    "# bonus: remove invalid predictions from COCO results JSON by giving COCO\n",
    "# dataset path to also filter out bbox results exceeding image height&width\n",
    "#coco_results = remove_invalid_coco_results(\"coco_dataset_ws/coco_result.json\", \"coco_dataset_ws/coco_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE\n",
    "#Get COCO with clipped bounding boxes:\n",
    "from sahi.utils.coco import Coco\n",
    "from sahi.utils.file import save_json\n",
    "\n",
    "# Clip overflowing bounding boxes to image width & height\n",
    "coco = Coco.from_coco_dict_or_path(coco_path, clip_bboxes_to_img_dims=True)\n",
    "\n",
    "#OR\n",
    "\n",
    "# apply to your already created coco object\n",
    "coco = coco.get_coco_with_clipped_bboxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IGNORE\n",
    "#Export your clipped_bboxed_coco:\n",
    "save_json(coco.json, \"coco.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6908535ef35668c3fddb4a34e0b01b146c763cd887a421acfda398fcf36f7233"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
