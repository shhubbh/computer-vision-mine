{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"/home/GIS_WS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1673413780278,
     "user": {
      "displayName": "Muhammad Ichsan",
      "userId": "14408332152811322711"
     },
     "user_tz": -420
    },
    "id": "5LOcHUjjQKic",
    "outputId": "725a5fd3-3600-4fcb-a239-d06706109990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/GIS_WS\n"
     ]
    }
   ],
   "source": [
    "home_direc = os.getcwd()\n",
    "print(home_direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1673413780892,
     "user": {
      "displayName": "Muhammad Ichsan",
      "userId": "14408332152811322711"
     },
     "user_tz": -420
    },
    "id": "dvXhQGYPRsIK"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import ExifTags\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng']  # acceptable image suffixes\n",
    "vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes\n",
    "\n",
    "# Get orientation exif tag\n",
    "for orientation in ExifTags.TAGS.keys():\n",
    "    if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "        break\n",
    "\n",
    "\n",
    "def exif_size(img):\n",
    "    # Returns exif-corrected PIL size\n",
    "    s = img.size  # (width, height)\n",
    "    try:\n",
    "        rotation = dict(img._getexif().items())[orientation]\n",
    "        if rotation in [6, 8]:  # rotation 270\n",
    "            s = (s[1], s[0])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def split_rows_simple(file='../data/sm4/out.txt'):  # from utils import *; split_rows_simple()\n",
    "    # splits one textfile into 3 smaller ones based upon train, test, val ratios\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    s = Path(file).suffix\n",
    "    lines = sorted(list(filter(lambda x: len(x) > 0, lines)))\n",
    "    i, j, k = split_indices(lines, train=0.9, test=0.1, validate=0.0)\n",
    "    for k, v in {'train': i, 'test': j, 'val': k}.items():  # key, value pairs\n",
    "        if v.any():\n",
    "            new_file = file.replace(s, f'_{k}{s}')\n",
    "            with open(new_file, 'w') as f:\n",
    "                f.writelines([lines[i] for i in v])\n",
    "\n",
    "\n",
    "def split_files(out_path, file_name, prefix_path=''):  # split training data\n",
    "    file_name = list(filter(lambda x: len(x) > 0, file_name))\n",
    "    file_name = sorted(file_name)\n",
    "    i, j, k = split_indices(file_name, train=0.9, test=0.1, validate=0.0)\n",
    "    datasets = {'train': i, 'test': j, 'val': k}\n",
    "    for key, item in datasets.items():\n",
    "        if item.any():\n",
    "            with open(f'{out_path}_{key}.txt', 'a') as file:\n",
    "                for i in item:\n",
    "                    file.write('%s%s\\n' % (prefix_path, file_name[i]))\n",
    "\n",
    "\n",
    "def split_indices(x, train=0.9, test=0.1, validate=0.0, shuffle=True):  # split training data\n",
    "    n = len(x)\n",
    "    v = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(v)\n",
    "\n",
    "    i = round(n * train)  # train\n",
    "    j = round(n * test) + i  # test\n",
    "    k = round(n * validate) + j  # validate\n",
    "    return v[:i], v[i:j], v[j:k]  # return indices\n",
    "\n",
    "\n",
    "def make_dirs(dir=dir):\n",
    "    # Create folders\n",
    "    dir = Path(dir)\n",
    "    if dir.exists():\n",
    "        shutil.rmtree(dir)  # delete dir\n",
    "    for p in dir, dir / 'labels', dir / 'images':\n",
    "        p.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "    return dir\n",
    "\n",
    "\n",
    "def write_data_data(fname='data.data', nc=80):\n",
    "    # write darknet *.data file\n",
    "    lines = ['classes = %g\\n' % nc,\n",
    "             'train =../out/data_train.txt\\n',\n",
    "             'valid =../out/data_test.txt\\n',\n",
    "             'names =../out/data.names\\n',\n",
    "             'backup = backup/\\n',\n",
    "             'eval = coco\\n']\n",
    "\n",
    "    with open(fname, 'a') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "def image_folder2file(folder='images/'):  # from utils import *; image_folder2file()\n",
    "    # write a txt file listing all imaged in folder\n",
    "    s = glob.glob(f'{folder}*.*')\n",
    "    with open(f'{folder[:-1]}.txt', 'w') as file:\n",
    "        for l in s:\n",
    "            file.write(l + '\\n')  # write image list\n",
    "\n",
    "\n",
    "def add_coco_background(path='../data/sm4/', n=1000):  # from utils import *; add_coco_background()\n",
    "    # add coco background to sm4 in outb.txt\n",
    "    p = f'{path}background'\n",
    "    if os.path.exists(p):\n",
    "        shutil.rmtree(p)  # delete output folder\n",
    "    os.makedirs(p)  # make new output folder\n",
    "\n",
    "    # copy images\n",
    "    for image in glob.glob('../coco/images/train2014/*.*')[:n]:\n",
    "        os.system(f'cp {image} {p}')\n",
    "\n",
    "    # add to outb.txt and make train, test.txt files\n",
    "    f = f'{path}out.txt'\n",
    "    fb = f'{path}outb.txt'\n",
    "    os.system(f'cp {f} {fb}')\n",
    "    with open(fb, 'a') as file:\n",
    "        file.writelines(i + '\\n' for i in glob.glob(f'{p}/*.*'))\n",
    "    split_rows_simple(file=fb)\n",
    "\n",
    "\n",
    "def create_single_class_dataset(path='../data/sm3'):  # from utils import *; create_single_class_dataset('../data/sm3/')\n",
    "    # creates a single-class version of an existing dataset\n",
    "    os.system(f'mkdir {path}_1cls')\n",
    "\n",
    "\n",
    "def flatten_recursive_folders(path='../../Downloads/data/sm4/'):  # from utils import *; flatten_recursive_folders()\n",
    "    # flattens nested folders in path/images and path/JSON into single folders\n",
    "    idir, jdir = f'{path}images/', f'{path}json/'\n",
    "    nidir, njdir = Path(f'{path}images_flat/'), Path(f'{path}json_flat/')\n",
    "    n = 0\n",
    "\n",
    "    # Create output folders\n",
    "    for p in [nidir, njdir]:\n",
    "        if os.path.exists(p):\n",
    "            shutil.rmtree(p)  # delete output folder\n",
    "        os.makedirs(p)  # make new output folder\n",
    "\n",
    "    for parent, dirs, files in os.walk(idir):\n",
    "        for f in tqdm(files, desc=parent):\n",
    "            f = Path(f)\n",
    "            stem, suffix = f.stem, f.suffix\n",
    "            if suffix.lower()[1:] in img_formats:\n",
    "                n += 1\n",
    "                stem_new = '%g_' % n + stem\n",
    "                image_new = nidir / (stem_new + suffix)  # converts all formats to *.jpg\n",
    "                json_new = njdir / f'{stem_new}.json'\n",
    "\n",
    "                image = parent / f\n",
    "                json = Path(parent.replace('images', 'json')) / str(f).replace(suffix, '.json')\n",
    "\n",
    "                os.system(\"cp '%s' '%s'\" % (json, json_new))\n",
    "                os.system(\"cp '%s' '%s'\" % (image, image_new))\n",
    "                # cv2.imwrite(str(image_new), cv2.imread(str(image)))\n",
    "\n",
    "    print('Flattening complete: %g jsons and images' % n)\n",
    "\n",
    "\n",
    "def coco91_to_coco80_class():  # converts 80-index (val2014) to 91-index (paper)\n",
    "    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "    x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, None, 24, 25, None,\n",
    "         None, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, None, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "         51, 52, 53, 54, 55, 56, 57, 58, 59, None, 60, None, None, 61, None, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
    "         None, 73, 74, 75, 76, 77, 78, 79, None]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 955,
     "status": "ok",
     "timestamp": 1673413781844,
     "user": {
      "displayName": "Muhammad Ichsan",
      "userId": "14408332152811322711"
     },
     "user_tz": -420
    },
    "id": "3BSTtuYGQ2jv"
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "def min_index(arr1, arr2):\n",
    "    \"\"\"Find a pair of indexes with the shortest distance. \n",
    "    Args:\n",
    "        arr1: (N, 2).\n",
    "        arr2: (M, 2).\n",
    "    Return:\n",
    "        a pair of indexes(tuple).\n",
    "    \"\"\"\n",
    "    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)\n",
    "    return np.unravel_index(np.argmin(dis, axis=None), dis.shape)\n",
    "\n",
    "\n",
    "def merge_multi_segment(segments):\n",
    "    \"\"\"Merge multi segments to one list.\n",
    "    Find the coordinates with min distance between each segment,\n",
    "    then connect these coordinates with one thin line to merge all \n",
    "    segments into one.\n",
    "\n",
    "    Args:\n",
    "        segments(List(List)): original segmentations in coco's json file.\n",
    "            like [segmentation1, segmentation2,...], \n",
    "            each segmentation is a list of coordinates.\n",
    "    \"\"\"\n",
    "    s = []\n",
    "    segments = [np.array(i).reshape(-1, 2) for i in segments]\n",
    "    idx_list = [[] for _ in range(len(segments))]\n",
    "\n",
    "    # record the indexes with min distance between each segment\n",
    "    for i in range(1, len(segments)):\n",
    "        idx1, idx2 = min_index(segments[i - 1], segments[i])\n",
    "        idx_list[i - 1].append(idx1)\n",
    "        idx_list[i].append(idx2)\n",
    "\n",
    "    # use two round to connect all the segments\n",
    "    for k in range(2):\n",
    "        # forward connection\n",
    "        if k == 0:\n",
    "            for i, idx in enumerate(idx_list):\n",
    "                # middle segments have two indexes\n",
    "                # reverse the index of middle segments\n",
    "                if len(idx) == 2 and idx[0] > idx[1]:\n",
    "                    idx = idx[::-1]\n",
    "                    segments[i] = segments[i][::-1, :]\n",
    "\n",
    "                segments[i] = np.roll(segments[i], -idx[0], axis=0)\n",
    "                segments[i] = np.concatenate([segments[i], segments[i][:1]])\n",
    "                # deal with the first segment and the last one\n",
    "                if i in [0, len(idx_list) - 1]:\n",
    "                    s.append(segments[i])\n",
    "                else:\n",
    "                    idx = [0, idx[1] - idx[0]]\n",
    "                    s.append(segments[i][idx[0]:idx[1] + 1])\n",
    "\n",
    "        else:\n",
    "            for i in range(len(idx_list) - 1, -1, -1):\n",
    "                if i not in [0, len(idx_list) - 1]:\n",
    "                    idx = idx_list[i]\n",
    "                    nidx = abs(idx[1] - idx[0])\n",
    "                    s.append(segments[i][nidx:])\n",
    "    return s\n",
    "\n",
    "\n",
    "def delete_dsstore(path='../datasets'):\n",
    "    # Delete apple .DS_store files\n",
    "    from pathlib import Path\n",
    "    files = list(Path(path).rglob('.DS_store'))\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        f.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673413781845,
     "user": {
      "displayName": "Muhammad Ichsan",
      "userId": "14408332152811322711"
     },
     "user_tz": -420
    },
    "id": "cW6tf1BXPgfJ"
   },
   "outputs": [],
   "source": [
    "def convert_bbox_coco2yolo(img_width, img_height, bbox):\n",
    "    \"\"\"\n",
    "    Convert bounding box from COCO  format to YOLO format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_width : int\n",
    "        width of image\n",
    "    img_height : int\n",
    "        height of image\n",
    "    bbox : list[int]\n",
    "        bounding box annotation in COCO format: \n",
    "        [top left x position, top left y position, width, height]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[float]\n",
    "        bounding box annotation in YOLO format: \n",
    "        [x_center_rel, y_center_rel, width_rel, height_rel]\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOLO bounding box format: [x_center, y_center, width, height]\n",
    "    # (float values relative to width and height of image)\n",
    "    x_tl, y_tl, w, h = bbox\n",
    "\n",
    "    dw = 1.0 / img_width\n",
    "    dh = 1.0 / img_height\n",
    "\n",
    "    x_center = x_tl + w / 2.0\n",
    "    y_center = y_tl + h / 2.0\n",
    "\n",
    "    x = x_center * dw\n",
    "    y = y_center * dh\n",
    "    w = w * dw\n",
    "    h = h * dh\n",
    "\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673413781845,
     "user": {
      "displayName": "Muhammad Ichsan",
      "userId": "14408332152811322711"
     },
     "user_tz": -420
    },
    "id": "vzGh_s9tPgfK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "def make_folders(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def convert_coco_json_to_yolo_txt(output_path, json_file,use_segments=True):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "    make_folders(output_path)\n",
    "\n",
    "    df_img_id = []\n",
    "    df_img_name = []\n",
    "    df_img_width = []\n",
    "    df_img_height = []\n",
    "    with open(json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "    print('ekstraksi dari json :',json_file)\n",
    "\n",
    "    # write _darknet.labels, which holds names of all classes (one class per line)\n",
    "    label_file = os.path.join(output_path, \"_darknet.labels.txt\")\n",
    "    with open(label_file, \"w\") as f:\n",
    "        for image in tqdm(json_data[\"images\"], desc=\"Annotation txt for each iamge\"):\n",
    "            img_id = image[\"id\"]\n",
    "            #img_name = image[\"file_name\"]\n",
    "            img_name = os.path.basename(image[\"file_name\"])\n",
    "            print(\"checking :\", img_name,\"and copying images to output path\")\n",
    "            json_images = os.path.dirname(json_file)+\"/\"+image[\"file_name\"]\n",
    "            \n",
    "            !cp -R {json_images} {output_path}\n",
    "            img_width = image[\"width\"]\n",
    "            img_height = image[\"height\"]\n",
    "            df_img_id.append(img_id)\n",
    "            df_img_name.append(img_name)\n",
    "            df_img_width.append(img_width)\n",
    "            df_img_height.append(img_height)\n",
    "        \n",
    "            anno_in_image = [anno for anno in json_data[\"annotations\"] if anno[\"image_id\"] == img_id]\n",
    "            #anno_txt = os.path.join(output_path, img_name.split(\".\")[0] + \".txt\")\n",
    "            anno_txt = os.path.join(output_path, img_name.replace(\".jpg\",\".txt\"))\n",
    "\n",
    "            h, w, f = image['height'], image['width'], image['file_name']\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            with open(anno_txt, \"w\") as f:\n",
    "                for anno in anno_in_image:\n",
    "                    category = anno[\"category_id\"]\n",
    "                    bbox_COCO = anno[\"bbox\"]\n",
    "                    #x, y, w, h = convert_bbox_coco2yolo(img_width, img_height, bbox_COCO)\n",
    "                    if anno['iscrowd']:\n",
    "                        continue\n",
    "                    # The COCO box format is [top left x, top left y, width, height]\n",
    "                    box = np.array(anno['bbox'], dtype=np.float64)\n",
    "                    box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "                    box[[0, 2]] /= w  # normalize x\n",
    "                    box[[1, 3]] /= h  # normalize y\n",
    "                    if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                        continue\n",
    "                    #cls = coco80[anno['category_id'] - 1] if cls91to80 else anno['category_id'] - 1  # class\n",
    "                    cls = anno['category_id'] - 1\n",
    "                    box = [cls] + box.tolist()\n",
    "                    if box not in bboxes:\n",
    "                        bboxes.append(box)\n",
    "                    # Segments\n",
    "                    if use_segments:\n",
    "                        if len(anno['segmentation']) > 1:\n",
    "                            s = merge_multi_segment(anno['segmentation'])\n",
    "                            s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                        else:\n",
    "                            s = [j for i in anno['segmentation'] for j in i]  # all segments concatenated\n",
    "                            s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                        s = [cls] + s\n",
    "                        if s not in segments:\n",
    "                            segments.append(s)\n",
    "\n",
    "                    last_iter=len(bboxes)-1\n",
    "                    line = *(segments[last_iter] if use_segments else bboxes[last_iter]),  # cls, box or segments\n",
    "                    f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "                print(\"that images contains class:\",len(bboxes),\"objects\")\n",
    "\n",
    "    #print(\"Converting COCO Json to YOLO txt finished!\")\n",
    "    #json_images = os.path.dirname(json_file)+\"/*.jpg\"\n",
    "    \n",
    "    #print(\"Copying images to output path\")\n",
    "    #!cp -R {json_images} {output_path}\n",
    "    \n",
    "    print(\"creating category_id and category name in darknet.labels\")\n",
    "    with open(label_file, \"w\") as f:\n",
    "        for category in tqdm(json_data[\"categories\"], desc=\"Categories\"):\n",
    "            category_name = category[\"name\"]\n",
    "            print(category_name)\n",
    "            f.write(f\"{category_name}\\n\")\n",
    "\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11736,
     "status": "ok",
     "timestamp": 1673413793578,
     "user": {
      "displayName": "Muhammad Ichsan",
      "userId": "14408332152811322711"
     },
     "user_tz": -420
    },
    "id": "0hbraoKMPgfN",
    "outputId": "ffb0f5d0-31dc-41cc-d80d-fa00e31a6e6c"
   },
   "outputs": [],
   "source": [
    "coco_annotation_direc = os.path.join(home_direc, 'images', 'annotation_coco.json')\n",
    "convert_coco_json_to_yolo_txt(\"yolo_data_from_coco\",coco_annotation_direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "83d9b93781df2ef451f03771cc8db44dcd3275d59589f0973dc63e92aba3936c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
